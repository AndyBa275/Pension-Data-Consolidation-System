{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b53f16e0-045d-4464-a32a-fcb24c34ea7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# =============================================================================\n",
    "# CONFIGURATION\n",
    "# =============================================================================\n",
    "\n",
    "# File paths\n",
    "CORRECTED_MASTER_FILE = r\"C:\\Users\\spt-admin\\Desktop\\PSWEPS_NEWADD\\NEW FOLDERS\\Master_Data_Corrected.csv\"\n",
    "SCHEDULES_FOLDER = r\"C:\\Users\\spt-admin\\Desktop\\PSWEPS_NEWSCHEDULES_DONE\"\n",
    "OUTPUT_FOLDER = r\"C:\\Users\\spt-admin\\Desktop\\PSWEPS_SCHEDULES\"\n",
    "\n",
    "# Create output folder if it doesn't exist\n",
    "if not os.path.exists(OUTPUT_FOLDER):\n",
    "    os.makedirs(OUTPUT_FOLDER)\n",
    "    print(f\"Created output folder: {OUTPUT_FOLDER}\")\n",
    "\n",
    "print(\"=\" * 80)\n",
    "print(\"EMPLOYEE NUMBER UPDATE - EMPLOYEE# + SSNIT MATCHING\")\n",
    "print(\"=\" * 80)\n",
    "print(f\"Started at: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\\n\")\n",
    "\n",
    "# =============================================================================\n",
    "# STEP 1: LOAD MASTER DATA AND CREATE MAPPING\n",
    "# =============================================================================\n",
    "\n",
    "print(\"Step 1: Loading master data and creating mapping dictionary...\")\n",
    "\n",
    "try:\n",
    "    master_df = pd.read_csv(CORRECTED_MASTER_FILE, dtype=str)\n",
    "    master_df.columns = master_df.columns.str.strip()\n",
    "    \n",
    "    # Fill NaN values\n",
    "    master_df['Employee_Number'] = master_df['Employee_Number'].fillna('').str.strip()\n",
    "    master_df['SSNIT_Number'] = master_df['SSNIT_Number'].fillna('').str.strip()\n",
    "    master_df['Original_Employee_Number'] = master_df['Original_Employee_Number'].fillna('').str.strip()\n",
    "    master_df['Status'] = master_df['Status'].fillna('').str.strip()\n",
    "    \n",
    "    # Create mapping dictionary\n",
    "    # Key: (Original_Employee_Number, SSNIT_Number)\n",
    "    # Value: {new_emp_num, status, employee_name}\n",
    "    mapping = {}\n",
    "    \n",
    "    for _, row in master_df.iterrows():\n",
    "        original_emp = row['Original_Employee_Number']\n",
    "        ssnit = row['SSNIT_Number']\n",
    "        \n",
    "        # Skip if either is empty or unknown\n",
    "        if original_emp in ['', 'EMPTY_EMP', 'UNKNOWN_EMP', 'UNKNOWN']:\n",
    "            continue\n",
    "        if ssnit in ['', 'UNKNOWN']:\n",
    "            continue\n",
    "        \n",
    "        key = (original_emp, ssnit)\n",
    "        mapping[key] = {\n",
    "            'new_emp_num': row['Employee_Number'],\n",
    "            'status': row['Status'],\n",
    "            'employee_name': row.get('Employee_Name', '')\n",
    "        }\n",
    "    \n",
    "    # Count statuses\n",
    "    kept_count = sum(1 for v in mapping.values() if 'Kept' in v['status'])\n",
    "    reassigned_count = sum(1 for v in mapping.values() if 'Reassigned' in v['status'])\n",
    "    \n",
    "    print(f\"Loaded {len(mapping)} mappings from master data\")\n",
    "    print(f\"  - Status 'Kept': {kept_count}\")\n",
    "    print(f\"  - Status 'Reassigned': {reassigned_count}\")\n",
    "    print(f\"  - Empty/Unknown employee numbers: Excluded from mapping\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"ERROR loading master file: {str(e)}\")\n",
    "    exit()\n",
    "\n",
    "# =============================================================================\n",
    "# PRE-VALIDATION: CHECK FOR DUPLICATE (EMPLOYEE#, SSNIT) PAIRS IN MASTER\n",
    "# =============================================================================\n",
    "\n",
    "print(\"\\nPre-validation: Checking for duplicate (Employee#, SSNIT) pairs in master...\")\n",
    "\n",
    "# Check for duplicates in master data\n",
    "master_check = master_df[\n",
    "    (master_df['Original_Employee_Number'] != '') & \n",
    "    (master_df['Original_Employee_Number'] != 'EMPTY_EMP') &\n",
    "    (master_df['Original_Employee_Number'] != 'UNKNOWN_EMP') &\n",
    "    (master_df['SSNIT_Number'] != '') &\n",
    "    (master_df['SSNIT_Number'] != 'UNKNOWN')\n",
    "].copy()\n",
    "\n",
    "duplicate_check = master_check.groupby(['Original_Employee_Number', 'SSNIT_Number']).size()\n",
    "duplicates = duplicate_check[duplicate_check > 1]\n",
    "\n",
    "if len(duplicates) > 0:\n",
    "    print(f\"WARNING: Found {len(duplicates)} duplicate (Employee#, SSNIT) pairs in master data:\")\n",
    "    for (emp, ssnit), count in duplicates.items():\n",
    "        print(f\"  - {emp} + {ssnit}: appears {count} times\")\n",
    "    print(\"  -> These may cause unexpected behavior. Review master data!\")\n",
    "else:\n",
    "    print(\"No duplicate (Employee#, SSNIT) pairs found in master data\")\n",
    "\n",
    "# =============================================================================\n",
    "# STEP 2: PROCESS ALL SCHEDULE FILES\n",
    "# =============================================================================\n",
    "\n",
    "print(\"\\nStep 2: Processing schedule files...\")\n",
    "print(\"-\" * 80)\n",
    "\n",
    "files_processed = 0\n",
    "files_updated = 0\n",
    "files_skipped = 0\n",
    "total_updates = 0\n",
    "total_rows_checked = 0\n",
    "total_empty_unknown_skipped = 0\n",
    "update_log = []\n",
    "error_log = []\n",
    "no_match_log = []\n",
    "\n",
    "# Walk through all directories\n",
    "for root, dirs, files in os.walk(SCHEDULES_FOLDER):\n",
    "    # Skip the output folder and analysis output folder\n",
    "    if OUTPUT_FOLDER in root or 'ANALYSIS_OUTPUT' in root:\n",
    "        continue\n",
    "    \n",
    "    for file in files:\n",
    "        ext = os.path.splitext(file)[1].lower()\n",
    "        \n",
    "        if ext in ['.xlsx', '.xls', '.xlsm']:\n",
    "            file_path = os.path.join(root, file)\n",
    "            relative_path = os.path.relpath(root, SCHEDULES_FOLDER)\n",
    "            \n",
    "            try:\n",
    "                files_processed += 1\n",
    "                print(f\"\\n[{files_processed}] Processing: {file}\")\n",
    "                \n",
    "                # Read all sheets\n",
    "                xl_file = pd.ExcelFile(file_path)\n",
    "                file_had_updates = False\n",
    "                sheets_data = {}\n",
    "                \n",
    "                for sheet_name in xl_file.sheet_names:\n",
    "                    try:\n",
    "                        # Read sheet\n",
    "                        df = pd.read_excel(file_path, sheet_name=sheet_name, dtype=str)\n",
    "                        \n",
    "                        # Get column names for A, B, C\n",
    "                        if len(df.columns) < 3:\n",
    "                            sheets_data[sheet_name] = df\n",
    "                            continue\n",
    "                        \n",
    "                        col_A = df.columns[0]  # Employee Number\n",
    "                        col_C = df.columns[2]  # SSNIT Number\n",
    "                        \n",
    "                        # Track updates in this sheet\n",
    "                        sheet_updates = 0\n",
    "                        rows_checked = 0\n",
    "                        empty_unknown_skipped = 0\n",
    "                        \n",
    "                        # Process each row\n",
    "                        for idx, row in df.iterrows():\n",
    "                            schedule_emp_num = str(row[col_A]).strip() if pd.notna(row[col_A]) else ''\n",
    "                            schedule_ssnit = str(row[col_C]).strip() if pd.notna(row[col_C]) else ''\n",
    "                            \n",
    "                            # Skip completely empty rows\n",
    "                            if schedule_emp_num == '' and schedule_ssnit == '':\n",
    "                                continue\n",
    "                            \n",
    "                            rows_checked += 1\n",
    "                            total_rows_checked += 1\n",
    "                            \n",
    "                            # === NEW: SKIP EMPTY/UNKNOWN EMPLOYEE NUMBERS ===\n",
    "                            if schedule_emp_num in ['', 'EMPTY_EMP', 'UNKNOWN_EMP', 'UNKNOWN', 'nan', 'None']:\n",
    "                                empty_unknown_skipped += 1\n",
    "                                total_empty_unknown_skipped += 1\n",
    "                                continue  # Leave as-is, no processing\n",
    "                            \n",
    "                            # Create lookup key\n",
    "                            key = (schedule_emp_num, schedule_ssnit)\n",
    "                            \n",
    "                            # Check if this combination exists in our mapping\n",
    "                            if key in mapping:\n",
    "                                mapping_info = mapping[key]\n",
    "                                \n",
    "                                # Check status\n",
    "                                if 'Reassigned' in mapping_info['status']:\n",
    "                                    # This person was reassigned a new employee number\n",
    "                                    new_emp_num = mapping_info['new_emp_num']\n",
    "                                    \n",
    "                                    # Update it!\n",
    "                                    df.at[idx, col_A] = new_emp_num\n",
    "                                    sheet_updates += 1\n",
    "                                    \n",
    "                                    update_log.append({\n",
    "                                        'FILE': file,\n",
    "                                        'SHEET': sheet_name,\n",
    "                                        'ROW': idx + 2,  # +2 for Excel row (header + 0-index)\n",
    "                                        'OLD_EMP_NUM': schedule_emp_num,\n",
    "                                        'SSNIT': schedule_ssnit,\n",
    "                                        'NEW_EMP_NUM': new_emp_num,\n",
    "                                        'STATUS': mapping_info['status']\n",
    "                                    })\n",
    "                                # If status is 'Kept', do nothing (continue)\n",
    "                            else:\n",
    "                                # No match found - log for review\n",
    "                                if schedule_emp_num not in ['', 'EMPTY_EMP', 'UNKNOWN_EMP', 'UNKNOWN']:\n",
    "                                    no_match_log.append({\n",
    "                                        'FILE': file,\n",
    "                                        'SHEET': sheet_name,\n",
    "                                        'ROW': idx + 2,\n",
    "                                        'EMPLOYEE_NUMBER': schedule_emp_num,\n",
    "                                        'SSNIT': schedule_ssnit,\n",
    "                                        'REASON': 'Not found in master data'\n",
    "                                    })\n",
    "                        \n",
    "                        sheets_data[sheet_name] = df\n",
    "                        \n",
    "                        if sheet_updates > 0:\n",
    "                            print(f\"  Sheet '{sheet_name}': {sheet_updates} updates | {rows_checked} rows checked | {empty_unknown_skipped} empty/unknown skipped\")\n",
    "                            file_had_updates = True\n",
    "                            total_updates += sheet_updates\n",
    "                        elif rows_checked > 0:\n",
    "                            print(f\"  Sheet '{sheet_name}': No updates | {rows_checked} rows checked | {empty_unknown_skipped} empty/unknown skipped\")\n",
    "                        \n",
    "                    except Exception as e:\n",
    "                        print(f\"  Error in sheet '{sheet_name}': {str(e)}\")\n",
    "                        error_log.append({\n",
    "                            'FILE': file,\n",
    "                            'SHEET': sheet_name,\n",
    "                            'ROW': 'N/A',\n",
    "                            'ISSUE': f'Sheet processing error: {str(e)}'\n",
    "                        })\n",
    "                        # Keep original sheet data\n",
    "                        sheets_data[sheet_name] = pd.read_excel(file_path, sheet_name=sheet_name)\n",
    "                \n",
    "                # Save the file\n",
    "                output_dir = os.path.join(OUTPUT_FOLDER, relative_path)\n",
    "                if not os.path.exists(output_dir):\n",
    "                    os.makedirs(output_dir)\n",
    "                \n",
    "                output_path = os.path.join(output_dir, file)\n",
    "                \n",
    "                # Write all sheets to new file\n",
    "                with pd.ExcelWriter(output_path, engine='openpyxl') as writer:\n",
    "                    for sheet_name, sheet_df in sheets_data.items():\n",
    "                        sheet_df.to_excel(writer, sheet_name=sheet_name, index=False)\n",
    "                \n",
    "                if file_had_updates:\n",
    "                    print(f\"  Saved with updates to: {relative_path}\\\\{file}\")\n",
    "                    files_updated += 1\n",
    "                else:\n",
    "                    print(f\"  Saved (no changes) to: {relative_path}\\\\{file}\")\n",
    "                    files_skipped += 1\n",
    "            \n",
    "            except Exception as e:\n",
    "                print(f\"  ERROR processing file: {str(e)}\")\n",
    "                error_log.append({\n",
    "                    'FILE': file,\n",
    "                    'SHEET': 'N/A',\n",
    "                    'ROW': 'N/A',\n",
    "                    'ISSUE': f'File processing error: {str(e)}'\n",
    "                })\n",
    "\n",
    "# =============================================================================\n",
    "# STEP 3: GENERATE REPORTS\n",
    "# =============================================================================\n",
    "\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"GENERATING REPORTS\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "# Save update log\n",
    "if update_log:\n",
    "    log_df = pd.DataFrame(update_log)\n",
    "    log_file = os.path.join(OUTPUT_FOLDER, \"Update_Log.csv\")\n",
    "    log_df.to_csv(log_file, index=False)\n",
    "    print(f\"Update log saved: {log_file} ({len(update_log)} updates)\")\n",
    "\n",
    "# Save no-match log\n",
    "if no_match_log:\n",
    "    no_match_df = pd.DataFrame(no_match_log)\n",
    "    no_match_file = os.path.join(OUTPUT_FOLDER, \"No_Match_Log.csv\")\n",
    "    no_match_df.to_csv(no_match_file, index=False)\n",
    "    print(f\"No-match log saved: {no_match_file} ({len(no_match_log)} records)\")\n",
    "\n",
    "# Save error log\n",
    "if error_log:\n",
    "    error_df = pd.DataFrame(error_log)\n",
    "    error_file = os.path.join(OUTPUT_FOLDER, \"Error_Log.csv\")\n",
    "    error_df.to_csv(error_file, index=False)\n",
    "    print(f\"Error log saved: {error_file} ({len(error_log)} errors)\")\n",
    "\n",
    "# Generate text report\n",
    "report = []\n",
    "report.append(\"=\" * 80)\n",
    "report.append(\"SCHEDULE UPDATE REPORT - EMPLOYEE# + SSNIT MATCHING\")\n",
    "report.append(\"=\" * 80)\n",
    "report.append(f\"Generated: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\")\n",
    "report.append(f\"Master File: {CORRECTED_MASTER_FILE}\")\n",
    "report.append(f\"Schedules Folder: {SCHEDULES_FOLDER}\")\n",
    "report.append(f\"Output Folder: {OUTPUT_FOLDER}\")\n",
    "report.append(\"\")\n",
    "\n",
    "report.append(\"=\" * 80)\n",
    "report.append(\"SUMMARY\")\n",
    "report.append(\"=\" * 80)\n",
    "report.append(f\"Mappings Loaded from Master:        {len(mapping):,}\")\n",
    "report.append(f\"  - Status 'Kept':                  {kept_count:,}\")\n",
    "report.append(f\"  - Status 'Reassigned':            {reassigned_count:,}\")\n",
    "report.append(\"\")\n",
    "report.append(f\"Schedule Files Processed:           {files_processed:,}\")\n",
    "report.append(f\"Schedule Files Updated:             {files_updated:,}\")\n",
    "report.append(f\"Schedule Files (No Changes):        {files_skipped:,}\")\n",
    "report.append(f\"Total Rows Checked:                 {total_rows_checked:,}\")\n",
    "report.append(f\"Empty/Unknown Employee# Skipped:    {total_empty_unknown_skipped:,}\")\n",
    "report.append(f\"Total Employee Number Updates:      {total_updates:,}\")\n",
    "report.append(f\"Records Not Found in Master:        {len(no_match_log):,}\")\n",
    "report.append(f\"Errors/Warnings:                    {len(error_log):,}\")\n",
    "report.append(\"\")\n",
    "\n",
    "report.append(\"=\" * 80)\n",
    "report.append(\"MATCHING LOGIC USED\")\n",
    "report.append(\"=\" * 80)\n",
    "report.append(\"For each row in schedule:\")\n",
    "report.append(\"1. Read Employee Number (Column A) and SSNIT Number (Column C)\")\n",
    "report.append(\"2. If Employee Number is EMPTY/UNKNOWN -> SKIP (leave as-is)\")\n",
    "report.append(\"3. Create key: (Employee_Number, SSNIT_Number)\")\n",
    "report.append(\"4. Look up key in Master_Data_Corrected.csv\")\n",
    "report.append(\"5. If found:\")\n",
    "report.append(\"   - Status = 'Kept' -> DO NOTHING (person kept their number)\")\n",
    "report.append(\"   - Status = 'Reassigned' -> UPDATE to new employee number\")\n",
    "report.append(\"6. If not found -> LOG for review (may need manual check)\")\n",
    "report.append(\"\")\n",
    "report.append(\"This approach:\")\n",
    "report.append(\"Matches on TWO fields (Employee# + SSNIT) for accuracy\")\n",
    "report.append(\"Preserves empty/unknown employee numbers\")\n",
    "report.append(\"Only updates records that were actually reassigned\")\n",
    "report.append(\"\")\n",
    "\n",
    "if update_log:\n",
    "    report.append(\"=\" * 80)\n",
    "    report.append(\"UPDATES BY FILE\")\n",
    "    report.append(\"=\" * 80)\n",
    "    \n",
    "    log_df = pd.DataFrame(update_log)\n",
    "    file_summary = log_df.groupby('FILE').size().reset_index(name='UPDATE_COUNT')\n",
    "    file_summary = file_summary.sort_values('UPDATE_COUNT', ascending=False)\n",
    "    \n",
    "    report.append(f\"{'FILE':<50} | {'UPDATES'}\")\n",
    "    report.append(\"-\" * 80)\n",
    "    for _, row in file_summary.head(20).iterrows():\n",
    "        report.append(f\"{row['FILE']:<50} | {row['UPDATE_COUNT']}\")\n",
    "    \n",
    "    if len(file_summary) > 20:\n",
    "        report.append(f\"... and {len(file_summary) - 20} more files\")\n",
    "    report.append(\"\")\n",
    "\n",
    "if no_match_log:\n",
    "    report.append(\"=\" * 80)\n",
    "    report.append(\"RECORDS NOT FOUND IN MASTER (Top 20)\")\n",
    "    report.append(\"=\" * 80)\n",
    "    report.append(\"These schedule records didn't match any master data:\")\n",
    "    report.append(\"Review these manually - they may be:\")\n",
    "    report.append(\"  - New employees not in master data\")\n",
    "    report.append(\"  - Typos in employee number or SSNIT\")\n",
    "    report.append(\"  - Data from before/after your master data period\")\n",
    "    report.append(\"\")\n",
    "    \n",
    "    no_match_df = pd.DataFrame(no_match_log)\n",
    "    emp_summary = no_match_df.groupby('EMPLOYEE_NUMBER').size().reset_index(name='COUNT')\n",
    "    emp_summary = emp_summary.sort_values('COUNT', ascending=False)\n",
    "    \n",
    "    report.append(f\"{'EMPLOYEE_NUMBER':<20} | {'OCCURRENCES'}\")\n",
    "    report.append(\"-\" * 80)\n",
    "    for _, row in emp_summary.head(20).iterrows():\n",
    "        report.append(f\"{row['EMPLOYEE_NUMBER']:<20} | {row['COUNT']}\")\n",
    "    \n",
    "    if len(emp_summary) > 20:\n",
    "        report.append(f\"... and {len(emp_summary) - 20} more employee numbers\")\n",
    "    report.append(\"\")\n",
    "\n",
    "if error_log:\n",
    "    report.append(\"=\" * 80)\n",
    "    report.append(\"ERRORS/WARNINGS\")\n",
    "    report.append(\"=\" * 80)\n",
    "    error_df = pd.DataFrame(error_log)\n",
    "    issue_summary = error_df.groupby('ISSUE').size().reset_index(name='COUNT')\n",
    "    \n",
    "    for _, row in issue_summary.iterrows():\n",
    "        report.append(f\"  - {row['ISSUE']}: {row['COUNT']} occurrences\")\n",
    "    report.append(\"\")\n",
    "    report.append(\"See Error_Log.csv for full details\")\n",
    "    report.append(\"\")\n",
    "\n",
    "report.append(\"=\" * 80)\n",
    "report.append(\"END OF REPORT\")\n",
    "report.append(\"=\" * 80)\n",
    "\n",
    "# Save text report\n",
    "report_file = os.path.join(OUTPUT_FOLDER, \"Schedule_Update_Report.txt\")\n",
    "with open(report_file, 'w', encoding='utf-8') as f:\n",
    "    f.write('\\n'.join(report))\n",
    "\n",
    "print(f\"Text report saved: {report_file}\")\n",
    "\n",
    "# =============================================================================\n",
    "# FINAL SUMMARY\n",
    "# =============================================================================\n",
    "\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"UPDATE COMPLETE!\")\n",
    "print(\"=\" * 80)\n",
    "print(f\"\\nSUMMARY:\")\n",
    "print(f\"  Files processed: {files_processed}\")\n",
    "print(f\"  Files with updates: {files_updated}\")\n",
    "print(f\"  Files without updates: {files_skipped}\")\n",
    "print(f\"  Total rows checked: {total_rows_checked:,}\")\n",
    "print(f\"  Empty/Unknown employee numbers skipped: {total_empty_unknown_skipped:,}\")\n",
    "print(f\"  Total employee number updates: {total_updates}\")\n",
    "print(f\"  Records not found in master: {len(no_match_log)}\")\n",
    "print(f\"  Errors/warnings: {len(error_log)}\")\n",
    "\n",
    "print(f\"\\nOUTPUT LOCATION:\")\n",
    "print(f\"  {OUTPUT_FOLDER}\")\n",
    "\n",
    "print(\"\\nFILES GENERATED:\")\n",
    "print(f\"  1. All schedule files (preserving folder structure)\")\n",
    "if update_log:\n",
    "    print(f\"  2. Update_Log.csv - Every change made ({len(update_log)} updates)\")\n",
    "if no_match_log:\n",
    "    print(f\"  3. No_Match_Log.csv - Records not found in master ({len(no_match_log)} records)\")\n",
    "print(f\"  4. Schedule_Update_Report.txt - Summary report\")\n",
    "if error_log:\n",
    "    print(f\"  5. Error_Log.csv - Issues found during processing ({len(error_log)} errors)\")\n",
    "\n",
    "print(\"\\nLOGIC APPLIED:\")\n",
    "print(\"  Matched using (Employee Number + SSNIT Number) combination\")\n",
    "print(\"  Updated ONLY when Status = 'Reassigned'\")\n",
    "print(\"  Left unchanged when Status = 'Kept'\")\n",
    "print(\"  SKIPPED all empty/unknown employee numbers (preserved as-is)\")\n",
    "\n",
    "print(\"\\nNEXT STEPS:\")\n",
    "print(\"  1. Review Update_Log.csv to see all changes made\")\n",
    "if no_match_log:\n",
    "    print(f\"  2. Check No_Match_Log.csv - {len(no_match_log)} records not found in master\")\n",
    "if error_log:\n",
    "    print(f\"  3. Check Error_Log.csv for processing errors\")\n",
    "print(\"  4. Verify a few files manually to ensure correctness\")\n",
    "print(\"  5. Original files remain in PSWEPS_NEW folder (untouched)\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"ALL DONE!\")\n",
    "print(\"=\" * 80)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
