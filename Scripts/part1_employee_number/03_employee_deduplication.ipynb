{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f515449e-c845-4183-a8bd-0658c0f7f9a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# CELL 1: Import Libraries and Setup\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from fuzzywuzzy import fuzz\n",
    "from collections import defaultdict\n",
    "import re\n",
    "from datetime import datetime\n",
    "import openpyxl\n",
    "from openpyxl.styles import Font, PatternFill, Alignment\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "print(\"Libraries imported successfully\")\n",
    "print(f\"Processing started at: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\")\n",
    "\n",
    "\n",
    "# CELL 2: Configuration and File Paths\n",
    "# =============================================================================\n",
    "# CONFIGURATION SETTINGS\n",
    "# =============================================================================\n",
    "\n",
    "# File paths\n",
    "INPUT_FILE = r\"C:\\Users\\spt-admin\\Desktop\\PSWEPS_NEWADD\\01_Master_Data.csv\"\n",
    "OUTPUT_DIR = r\"C:\\Users\\spt-admin\\Desktop\\PSWEPS_NEWADD\\NEW FOLDERS\"\n",
    "\n",
    "# Processing parameters\n",
    "FUZZY_MATCH_THRESHOLD = 80  # Name similarity threshold (80%)\n",
    "SSNIT_TEMP_PATTERN = r'^\\d+$'  # Numeric only\n",
    "SSNIT_PERM_PATTERN = r'^[A-Z]\\d{12}$'  # Letter + 12 digits\n",
    "\n",
    "print(\"Configuration loaded:\")\n",
    "print(f\"  Input file: {INPUT_FILE}\")\n",
    "print(f\"  Output directory: {OUTPUT_DIR}\")\n",
    "print(f\"  Fuzzy match threshold: {FUZZY_MATCH_THRESHOLD}%\")\n",
    "\n",
    "\n",
    "# CELL 3: Load Data\n",
    "# =============================================================================\n",
    "# LOAD INPUT DATA\n",
    "# =============================================================================\n",
    "\n",
    "print(\"\\nLoading data...\")\n",
    "try:\n",
    "    df = pd.read_csv(INPUT_FILE, dtype=str)\n",
    "except FileNotFoundError:\n",
    "    print(f\"ERROR: The file was not found at the specified path.\")\n",
    "    print(f\"Please check this path is correct: {INPUT_FILE}\")\n",
    "    exit() # Stop the script if the file isn't found\n",
    "\n",
    "# Standardize column names by stripping whitespace\n",
    "df.columns = df.columns.str.strip()\n",
    "\n",
    "print(\"Columns found in CSV:\", df.columns.tolist())\n",
    "\n",
    "# --- TAILORED COLUMN MAPPING ---\n",
    "# This logic now exactly matches your file's headers.\n",
    "column_mapping = {}\n",
    "for col in df.columns:\n",
    "    col_lower = col.lower()\n",
    "    if col_lower == 'employee_number':\n",
    "        column_mapping[col] = 'Employee_Number'\n",
    "    elif col_lower == 'full_name': # Specifically looks for 'full_name'\n",
    "        column_mapping[col] = 'Employee_Name'\n",
    "    elif col_lower == 'ssnit_number':\n",
    "        column_mapping[col] = 'SSNIT_Number'\n",
    "\n",
    "df.rename(columns=column_mapping, inplace=True)\n",
    "\n",
    "# Check if the essential columns were found after renaming\n",
    "required_cols = ['Employee_Number', 'Employee_Name', 'SSNIT_Number']\n",
    "for col in required_cols:\n",
    "    if col not in df.columns:\n",
    "        print(f\"\\nCRITICAL ERROR: Could not find the required column '{col}'.\")\n",
    "        print(f\"Please ensure your CSV has the columns EMPLOYEE_NUMBER, FULL_NAME, and SSNIT_NUMBER.\")\n",
    "        exit()\n",
    "\n",
    "# Fill NaN values\n",
    "df['Employee_Number'] = df['Employee_Number'].fillna('UNKNOWN_EMP')\n",
    "df['Employee_Name'] = df['Employee_Name'].fillna('UNKNOWN_NAME')\n",
    "df['SSNIT_Number'] = df['SSNIT_Number'].fillna('UNKNOWN')\n",
    "\n",
    "# Strip whitespace\n",
    "df['Employee_Number'] = df['Employee_Number'].str.strip()\n",
    "df['Employee_Name'] = df['Employee_Name'].str.strip()\n",
    "df['SSNIT_Number'] = df['SSNIT_Number'].str.strip()\n",
    "\n",
    "print(f\"\\n Data loaded: {len(df)} records\")\n",
    "print(f\"  Unique Employee Numbers: {df['Employee_Number'].nunique()}\")\n",
    "print(f\"  Unique Names: {df['Employee_Name'].nunique()}\")\n",
    "print(f\"  Unique SSNITs: {df['SSNIT_Number'].nunique()}\")\n",
    "print(\"\\nSample data:\")\n",
    "print(df.head())\n",
    "\n",
    "# CELL 4: Helper Functions - SSNIT Classification\n",
    "# =============================================================================\n",
    "# HELPER FUNCTIONS - SSNIT CLASSIFICATION\n",
    "# =============================================================================\n",
    "\n",
    "def classify_ssnit(ssnit):\n",
    "    \"\"\"\n",
    "    Classify SSNIT as temporary, permanent, or unknown\n",
    "    Returns: 'temp', 'perm', or 'unknown'\n",
    "    \"\"\"\n",
    "    if pd.isna(ssnit) or str(ssnit).strip() in ['', 'UNKNOWN', 'nan', 'None']:\n",
    "        return 'unknown'\n",
    "    \n",
    "    ssnit = str(ssnit).strip()\n",
    "    \n",
    "    # Check for permanent SSNIT (starts with letter, 13 chars total)\n",
    "    if re.match(SSNIT_PERM_PATTERN, ssnit):\n",
    "        return 'perm'\n",
    "    \n",
    "    # Check for temporary SSNIT (numeric only)\n",
    "    if re.match(SSNIT_TEMP_PATTERN, ssnit):\n",
    "        return 'temp'\n",
    "    \n",
    "    return 'unknown'\n",
    "\n",
    "def validate_ssnit_combination(ssnit_list):\n",
    "    \"\"\"\n",
    "    Check if SSNIT combination is valid for a single person\n",
    "    Returns: (is_valid, violation_reason)\n",
    "    \"\"\"\n",
    "    if not ssnit_list:\n",
    "        return True, None\n",
    "    \n",
    "    # Classify all SSNITs\n",
    "    temp_ssnits = [s for s in ssnit_list if classify_ssnit(s) == 'temp']\n",
    "    perm_ssnits = [s for s in ssnit_list if classify_ssnit(s) == 'perm']\n",
    "    \n",
    "    # Check for violations\n",
    "    if len(temp_ssnits) > 1:\n",
    "        return False, f\"Multiple temporary SSNITs: {temp_ssnits}\"\n",
    "    \n",
    "    if len(perm_ssnits) > 1:\n",
    "        return False, f\"Multiple permanent SSNITs: {perm_ssnits}\"\n",
    "    \n",
    "    return True, None\n",
    "\n",
    "# Test the functions\n",
    "test_ssnits = ['454621', 'H123981259123', 'UNKNOWN']\n",
    "print(\"Testing SSNIT classification:\")\n",
    "for ssnit in test_ssnits:\n",
    "    print(f\"  {ssnit}: {classify_ssnit(ssnit)}\")\n",
    "\n",
    "print(\"\\nTesting SSNIT validation:\")\n",
    "print(f\"  [454621]: {validate_ssnit_combination(['454621'])}\")\n",
    "print(f\"  [454621, H123981259123]: {validate_ssnit_combination(['454621', 'H123981259123'])}\")\n",
    "print(f\"  [454621, 789012]: {validate_ssnit_combination(['454621', '789012'])}\")\n",
    "\n",
    "\n",
    "# CELL 5: Helper Functions - Name Matching\n",
    "# =============================================================================\n",
    "# HELPER FUNCTIONS - NAME MATCHING\n",
    "# =============================================================================\n",
    "\n",
    "def fuzzy_name_match(name1, name2, threshold=FUZZY_MATCH_THRESHOLD):\n",
    "    \"\"\"\n",
    "    Check if two names are similar enough to be the same person\n",
    "    Uses token_sort_ratio for better matching of reordered names\n",
    "    \"\"\"\n",
    "    if pd.isna(name1) or pd.isna(name2):\n",
    "        return False\n",
    "    \n",
    "    name1 = str(name1).strip().lower()\n",
    "    name2 = str(name2).strip().lower()\n",
    "    \n",
    "    if name1 == name2:\n",
    "        return True\n",
    "    \n",
    "    # Use token_sort_ratio to handle \"John Smith\" vs \"Smith, John\"\n",
    "    score = fuzz.token_sort_ratio(name1, name2)\n",
    "    return score >= threshold\n",
    "\n",
    "def group_similar_names(names):\n",
    "    \"\"\"\n",
    "    Group similar names together using fuzzy matching\n",
    "    Returns: list of lists (each inner list is a group of similar names)\n",
    "    \"\"\"\n",
    "    names = list(set(names))  # Remove exact duplicates\n",
    "    groups = []\n",
    "    \n",
    "    for name in names:\n",
    "        # Check if this name matches any existing group\n",
    "        added = False\n",
    "        for group in groups:\n",
    "            if any(fuzzy_name_match(name, existing_name) for existing_name in group):\n",
    "                group.append(name)\n",
    "                added = True\n",
    "                break\n",
    "        \n",
    "        # If no match found, create new group\n",
    "        if not added:\n",
    "            groups.append([name])\n",
    "    \n",
    "    return groups\n",
    "\n",
    "# Test fuzzy matching\n",
    "test_names = [\"Kankoh Martin\", \"Martin, Kankoh\", \"Martin K.\", \"Millicent Aidoo\"]\n",
    "print(\"Testing name grouping:\")\n",
    "groups = group_similar_names(test_names)\n",
    "for i, group in enumerate(groups, 1):\n",
    "    print(f\"  Group {i}: {group}\")\n",
    "\n",
    "\n",
    "# CELL 6: Core Algorithm - Process Employee Numbers\n",
    "# =============================================================================\n",
    "# CORE ALGORITHM - PROCESS EACH EMPLOYEE NUMBER\n",
    "# =============================================================================\n",
    "\n",
    "def process_employee_number(emp_num, emp_df):\n",
    "    \"\"\"\n",
    "    Process all records for a single employee number\n",
    "    Returns: list of person dictionaries\n",
    "    \"\"\"\n",
    "    # Step 1: Get all records for this employee number\n",
    "    records = emp_df[emp_df['Employee_Number'] == emp_num].copy()\n",
    "    \n",
    "    # Handle UNKNOWN SSNIT rule\n",
    "    if len(records) > 1:\n",
    "        # If shared, remove UNKNOWN records\n",
    "        records = records[records['SSNIT_Number'] != 'UNKNOWN']\n",
    "    # If only one person, keep UNKNOWN (no filtering needed)\n",
    "    \n",
    "    if len(records) == 0:\n",
    "        return []\n",
    "    \n",
    "    # Step 2: Group by similar names\n",
    "    unique_names = records['Employee_Name'].unique()\n",
    "    name_groups = group_similar_names(unique_names)\n",
    "    \n",
    "    persons = []\n",
    "    \n",
    "    # Step 3: Process each name group\n",
    "    for name_group in name_groups:\n",
    "        # Get all records for this name group\n",
    "        group_records = records[records['Employee_Name'].isin(name_group)]\n",
    "        \n",
    "        # Get all SSNITs for this name group\n",
    "        ssnits = group_records['SSNIT_Number'].unique().tolist()\n",
    "        ssnits = [s for s in ssnits if s != 'UNKNOWN']  # Exclude UNKNOWN\n",
    "        \n",
    "        # Step 4: Validate SSNIT combination\n",
    "        is_valid, violation = validate_ssnit_combination(ssnits)\n",
    "        \n",
    "        if is_valid:\n",
    "            # Single person\n",
    "            persons.append({\n",
    "                'names': name_group,\n",
    "                'primary_name': name_group[0],\n",
    "                'ssnits': ssnits,\n",
    "                'records': group_records,\n",
    "                'count': len(group_records)\n",
    "            })\n",
    "        else:\n",
    "            # Need to split by SSNIT combination\n",
    "            # Group records by their specific SSNIT combinations\n",
    "            ssnit_combinations = defaultdict(list)\n",
    "            \n",
    "            for _, row in group_records.iterrows():\n",
    "                # Get all SSNITs for this specific record's context\n",
    "                # (all records with same name AND same set of SSNITs)\n",
    "                record_ssnits = tuple(sorted([row['SSNIT_Number']]))\n",
    "                ssnit_combinations[record_ssnits].append(row)\n",
    "            \n",
    "            # Create a person for each valid SSNIT combination\n",
    "            for ssnit_combo, combo_records in ssnit_combinations.items():\n",
    "                combo_df = pd.DataFrame(combo_records)\n",
    "                persons.append({\n",
    "                    'names': name_group,\n",
    "                    'primary_name': name_group[0],\n",
    "                    'ssnits': list(ssnit_combo),\n",
    "                    'records': combo_df,\n",
    "                    'count': len(combo_df)\n",
    "                })\n",
    "    \n",
    "    # Step 5: Merge persons who share SSNITs\n",
    "    merged_persons = []\n",
    "    used_indices = set()\n",
    "    \n",
    "    for i, person1 in enumerate(persons):\n",
    "        if i in used_indices:\n",
    "            continue\n",
    "        \n",
    "        # Check if this person shares SSNITs with any other person\n",
    "        merged = person1.copy()\n",
    "        used_indices.add(i)\n",
    "        \n",
    "        for j, person2 in enumerate(persons[i+1:], start=i+1):\n",
    "            if j in used_indices:\n",
    "                continue\n",
    "            \n",
    "            # Check for shared SSNITs\n",
    "            shared_ssnits = set(person1['ssnits']) & set(person2['ssnits'])\n",
    "            \n",
    "            if shared_ssnits:\n",
    "                # Merge these persons\n",
    "                merged['names'] = list(set(merged['names'] + person2['names']))\n",
    "                merged['primary_name'] = '/'.join(sorted(set(merged['names'])))\n",
    "                merged['ssnits'] = list(set(merged['ssnits'] + person2['ssnits']))\n",
    "                merged['records'] = pd.concat([merged['records'], person2['records']])\n",
    "                merged['count'] = len(merged['records'])\n",
    "                used_indices.add(j)\n",
    "        \n",
    "        merged_persons.append(merged)\n",
    "    \n",
    "    return merged_persons\n",
    "\n",
    "print(\" Core processing function defined\")\n",
    "\n",
    "\n",
    "# CELL 7: Process All Employee Numbers\n",
    "# =============================================================================\n",
    "# PROCESS ALL EMPLOYEE NUMBERS\n",
    "# =============================================================================\n",
    "\n",
    "print(\"\\nProcessing all employee numbers...\")\n",
    "print(\"This may take a few minutes depending on data size...\")\n",
    "\n",
    "all_persons = []\n",
    "problematic_emp_numbers = {}\n",
    "\n",
    "unique_emp_numbers = df['Employee_Number'].unique()\n",
    "\n",
    "for idx, emp_num in enumerate(unique_emp_numbers, 1):\n",
    "    if idx % 100 == 0:\n",
    "        print(f\"  Processed {idx}/{len(unique_emp_numbers)} employee numbers...\")\n",
    "    \n",
    "    persons = process_employee_number(emp_num, df)\n",
    "    \n",
    "    # Track original employee number for each person\n",
    "    for person in persons:\n",
    "        person['original_emp_num'] = emp_num\n",
    "        all_persons.append(person)\n",
    "    \n",
    "    # Track problematic cases\n",
    "    if len(persons) > 1:\n",
    "        problematic_emp_numbers[emp_num] = {\n",
    "            'person_count': len(persons),\n",
    "            'persons': persons\n",
    "        }\n",
    "\n",
    "print(f\"\\n Processing complete!\")\n",
    "print(f\"  Total persons identified: {len(all_persons)}\")\n",
    "print(f\"  Employee numbers with multiple people: {len(problematic_emp_numbers)}\")\n",
    "\n",
    "\n",
    "# CELL 8: Assign New Employee Numbers\n",
    "# =============================================================================\n",
    "# ASSIGN NEW EMPLOYEE NUMBERS\n",
    "# =============================================================================\n",
    "\n",
    "print(\"\\nAssigning employee numbers...\")\n",
    "\n",
    "# Find highest existing employee number\n",
    "def extract_number(emp_num):\n",
    "    \"\"\"Extract numeric portion from employee number\"\"\"\n",
    "    try:\n",
    "        # Try to convert entire string to number\n",
    "        return int(emp_num)\n",
    "    except:\n",
    "        # Extract numbers from string\n",
    "        numbers = re.findall(r'\\d+', str(emp_num))\n",
    "        if numbers:\n",
    "            return int(numbers[-1])  # Return last number found\n",
    "        return 0\n",
    "\n",
    "max_number = max([extract_number(enum) for enum in df['Employee_Number'].unique()])\n",
    "next_number = max_number + 1\n",
    "\n",
    "print(f\"  Highest existing number: {max_number}\")\n",
    "print(f\"  Starting new assignments from: {next_number}\")\n",
    "\n",
    "# For each problematic employee number, assign new numbers\n",
    "assignment_log = []\n",
    "\n",
    "for emp_num, info in problematic_emp_numbers.items():\n",
    "    persons = info['persons']\n",
    "    \n",
    "    # Sort by count (descending) - most occurrences first\n",
    "    persons_sorted = sorted(persons, key=lambda x: (-x['count'], x['primary_name']))\n",
    "    \n",
    "    # First person keeps original number\n",
    "    winner = persons_sorted[0]\n",
    "    winner['new_emp_num'] = emp_num\n",
    "    winner['status'] = 'Kept'\n",
    "    winner['reason'] = f\"Most occurrences ({winner['count']})\"\n",
    "    \n",
    "    assignment_log.append({\n",
    "        'old_emp_num': emp_num,\n",
    "        'new_emp_num': emp_num,\n",
    "        'name': winner['primary_name'],\n",
    "        'ssnits': ';'.join(winner['ssnits']),\n",
    "        'count': winner['count'],\n",
    "        'status': 'Kept',\n",
    "        'reason': winner['reason']\n",
    "    })\n",
    "    \n",
    "    # Others get new numbers\n",
    "    for person in persons_sorted[1:]:\n",
    "        person['new_emp_num'] = str(next_number)\n",
    "        person['status'] = 'Reassigned'\n",
    "        \n",
    "        # Determine reason\n",
    "        if len([s for s in person['ssnits'] if classify_ssnit(s) == 'temp']) > 1:\n",
    "            person['reason'] = \"2+ temporary SSNITs detected\"\n",
    "        elif len([s for s in person['ssnits'] if classify_ssnit(s) == 'perm']) > 1:\n",
    "            person['reason'] = \"2+ permanent SSNITs detected\"\n",
    "        else:\n",
    "            person['reason'] = \"Shared employee number\"\n",
    "        \n",
    "        assignment_log.append({\n",
    "            'old_emp_num': emp_num,\n",
    "            'new_emp_num': str(next_number),\n",
    "            'name': person['primary_name'],\n",
    "            'ssnits': ';'.join(person['ssnits']),\n",
    "            'count': person['count'],\n",
    "            'status': 'Reassigned',\n",
    "            'reason': person['reason']\n",
    "        })\n",
    "        \n",
    "        next_number += 1\n",
    "\n",
    "# Handle persons who had no conflicts (kept original numbers)\n",
    "for person in all_persons:\n",
    "    if 'new_emp_num' not in person:\n",
    "        person['new_emp_num'] = person['original_emp_num']\n",
    "        person['status'] = 'Kept'\n",
    "        person['reason'] = 'No sharing detected'\n",
    "\n",
    "print(f\" Assignment complete!\")\n",
    "print(f\"  New employee numbers generated: {next_number - max_number - 1}\")\n",
    "\n",
    "\n",
    "# CELL 9: Generate Output File 1 - Master_Data_Corrected.csv\n",
    "# =============================================================================\n",
    "# OUTPUT FILE 1: Master_Data_Corrected.csv\n",
    "# =============================================================================\n",
    "\n",
    "print(\"\\nGenerating Master_Data_Corrected.csv...\")\n",
    "\n",
    "corrected_records = []\n",
    "\n",
    "for person in all_persons:\n",
    "    for _, record in person['records'].iterrows():\n",
    "        corrected_records.append({\n",
    "            'Employee_Number': person['new_emp_num'],\n",
    "            'Employee_Name': record['Employee_Name'],\n",
    "            'SSNIT_Number': record['SSNIT_Number'],\n",
    "            'Original_Employee_Number': person['original_emp_num'],\n",
    "            'Status': person['status'],\n",
    "            'Record_Count': person['count']\n",
    "        })\n",
    "\n",
    "df_corrected = pd.DataFrame(corrected_records)\n",
    "\n",
    "# Sort by new employee number\n",
    "df_corrected = df_corrected.sort_values('Employee_Number')\n",
    "\n",
    "output_file = f\"{OUTPUT_DIR}\\\\Master_Data_Corrected.csv\"\n",
    "df_corrected.to_csv(output_file, index=False)\n",
    "\n",
    "print(f\" Saved: {output_file}\")\n",
    "print(f\"  Total records: {len(df_corrected)}\")\n",
    "\n",
    "\n",
    "# CELL 10: Generate Output File 2 - Employee_Number_Mapping.csv\n",
    "# =============================================================================\n",
    "# OUTPUT FILE 2: Employee_Number_Mapping.csv\n",
    "# =============================================================================\n",
    "\n",
    "print(\"\\nGenerating Employee_Number_Mapping.csv...\")\n",
    "\n",
    "df_mapping = pd.DataFrame(assignment_log)\n",
    "\n",
    "# Add all persons who kept original numbers and had no conflicts\n",
    "for person in all_persons:\n",
    "    if person['original_emp_num'] not in problematic_emp_numbers:\n",
    "        df_mapping = pd.concat([df_mapping, pd.DataFrame([{\n",
    "            'old_emp_num': person['original_emp_num'],\n",
    "            'new_emp_num': person['new_emp_num'],\n",
    "            'name': person['primary_name'],\n",
    "            'ssnits': ';'.join(person['ssnits']),\n",
    "            'count': person['count'],\n",
    "            'status': 'Kept',\n",
    "            'reason': 'No sharing detected'\n",
    "        }])], ignore_index=True)\n",
    "\n",
    "# Rename columns for output\n",
    "df_mapping.columns = ['Old_Employee_Number', 'New_Employee_Number', 'Person_Name', \n",
    "                      'All_SSNITs', 'Record_Count', 'Action', 'Reason']\n",
    "\n",
    "# Sort by old employee number\n",
    "df_mapping = df_mapping.sort_values('Old_Employee_Number')\n",
    "\n",
    "output_file = f\"{OUTPUT_DIR}\\\\Employee_Number_Mapping.csv\"\n",
    "df_mapping.to_csv(output_file, index=False)\n",
    "\n",
    "print(f\" Saved: {output_file}\")\n",
    "print(f\"  Total mappings: {len(df_mapping)}\")\n",
    "# CELL 11: Generate Output File 3 - Duplicate_Resolution_Report.txt\n",
    "# =============================================================================\n",
    "# OUTPUT FILE 3: Duplicate_Resolution_Report.txt\n",
    "# =============================================================================\n",
    "\n",
    "print(\"\\nGenerating Duplicate_Resolution_Report.txt...\")\n",
    "\n",
    "report = []\n",
    "report.append(\"=\" * 80)\n",
    "report.append(\"EMPLOYEE NUMBER DEDUPLICATION REPORT\")\n",
    "report.append(\"=\" * 80)\n",
    "report.append(f\"Generated: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\")\n",
    "report.append(f\"Input File: {INPUT_FILE}\")\n",
    "report.append(f\"Output Location: {OUTPUT_DIR}\")\n",
    "report.append(\"\")\n",
    "\n",
    "report.append(\"=\" * 80)\n",
    "report.append(\"SUMMARY STATISTICS\")\n",
    "report.append(\"=\" * 80)\n",
    "report.append(f\"Total Records Processed:                   {len(df):,}\")\n",
    "report.append(f\"Unique Employee Numbers (Before):        {df['Employee_Number'].nunique():,}\")\n",
    "report.append(f\"Unique Employee Numbers (After):         {df_corrected['Employee_Number'].nunique():,}\")\n",
    "report.append(f\"New Employee Numbers Generated:          {next_number - max_number - 1:,}\")\n",
    "report.append(f\"Employee Numbers with Sharing Resolved:    {len(problematic_emp_numbers):,}\")\n",
    "report.append(\"\")\n",
    "\n",
    "report.append(\"=\" * 80)\n",
    "report.append(\"ISSUES IDENTIFIED\")\n",
    "report.append(\"=\" * 80)\n",
    "report.append(f\"Employee Numbers with Multiple People:     {len(problematic_emp_numbers):,}\")\n",
    "\n",
    "# Count specific issue types\n",
    "temp_violations = sum(1 for p in all_persons if '2+ temporary SSNITs' in p.get('reason', ''))\n",
    "perm_violations = sum(1 for p in all_persons if '2+ permanent SSNITs' in p.get('reason', ''))\n",
    "shared_ssnit_merges = sum(1 for p in all_persons if '/' in p['primary_name'])\n",
    "\n",
    "report.append(f\"- 2+ Temporary SSNITs Detected:          {temp_violations:,} cases\")\n",
    "report.append(f\"- 2+ Permanent SSNITs Detected:          {perm_violations:,} cases\")\n",
    "report.append(f\"- Name Groups Merged by Shared SSNIT:    {shared_ssnit_merges:,} cases\")\n",
    "report.append(\"\")\n",
    "\n",
    "report.append(\"=\" * 80)\n",
    "report.append(\"ACTIONS TAKEN\")\n",
    "report.append(\"=\" * 80)\n",
    "kept_count = sum(1 for p in all_persons if p['status'] == 'Kept')\n",
    "reassigned_count = sum(1 for p in all_persons if p['status'] == 'Reassigned')\n",
    "report.append(f\"Original Employee Numbers Kept:          {kept_count:,} people\")\n",
    "report.append(f\"New Employee Numbers Assigned:           {reassigned_count:,} people\")\n",
    "report.append(\"\")\n",
    "\n",
    "report.append(\"=\" * 80)\n",
    "report.append(\"TOP 10 MOST PROBLEMATIC EMPLOYEE NUMBERS\")\n",
    "report.append(\"=\" * 80)\n",
    "report.append(f\"{'Rank':<6}| {'Old_Emp_No':<12}| {'People':<8}| {'Names_List'}\")\n",
    "report.append(\"-\" * 80)\n",
    "\n",
    "# Sort problematic employee numbers by person count\n",
    "top_problems = sorted(problematic_emp_numbers.items(), \n",
    "                      key=lambda x: x[1]['person_count'], \n",
    "                      reverse=True)[:10]\n",
    "\n",
    "for rank, (emp_num, info) in enumerate(top_problems, 1):\n",
    "    names = '; '.join([p['primary_name'] for p in info['persons']])\n",
    "    if len(names) > 50:\n",
    "        names = names[:47] + \"...\"\n",
    "    report.append(f\"{rank:<6}| {emp_num:<12}| {info['person_count']:<8}| {names}\")\n",
    "\n",
    "report.append(\"\")\n",
    "\n",
    "report.append(\"=\" * 80)\n",
    "report.append(\"NEW EMPLOYEE NUMBER ALLOCATION\")\n",
    "report.append(\"=\" * 80)\n",
    "report.append(f\"Number Generation Method: Sequential from highest existing\")\n",
    "report.append(f\"Highest Existing Number Found: {max_number}\")\n",
    "report.append(f\"New Numbers Assigned Range: {max_number + 1} - {next_number - 1}\")\n",
    "report.append(\"\")\n",
    "\n",
    "report.append(\"=\" * 80)\n",
    "report.append(\"FUZZY NAME MATCHING RESULTS\")\n",
    "report.append(\"=\" * 80)\n",
    "report.append(f\"Fuzzy Matching Threshold: {FUZZY_MATCH_THRESHOLD}%\")\n",
    "report.append(f\"Total Persons Identified: {len(all_persons):,}\")\n",
    "report.append(\"\")\n",
    "\n",
    "report.append(\"=\" * 80)\n",
    "report.append(\"NEXT STEPS\")\n",
    "report.append(\"=\" * 80)\n",
    "report.append(\"1. Review 'Records_For_Manual_Review.csv' for flagged cases\")\n",
    "report.append(\"2. Use 'Employee_Number_Mapping.csv' to update your 2010-2025 schedules\")\n",
    "report.append(\"3. Use 'Reassigned_Employee_Numbers_Register.xlsx' as quick reference\")\n",
    "report.append(\"4. Keep 'Master_Data_Corrected.csv' as your new clean master list\")\n",
    "report.append(\"\")\n",
    "\n",
    "report.append(\"=\" * 80)\n",
    "report.append(\"END OF REPORT\")\n",
    "report.append(\"=\" * 80)\n",
    "\n",
    "# Write report\n",
    "output_file = f\"{OUTPUT_DIR}\\\\Duplicate_Resolution_Report.txt\"\n",
    "# --- THIS IS THE LINE THAT WAS FIXED ---\n",
    "with open(output_file, 'w', encoding='utf-8') as f:\n",
    "    f.write('\\n'.join(report))\n",
    "\n",
    "print(f\" Saved: {output_file}\")\n",
    "\n",
    "# CELL 12: Generate Output File 4 - Records_For_Manual_Review.csv\n",
    "# =============================================================================\n",
    "# OUTPUT FILE 4: Records_For_Manual_Review.csv\n",
    "# =============================================================================\n",
    "\n",
    "print(\"\\nGenerating Records_For_Manual_Review.csv...\")\n",
    "\n",
    "manual_review = []\n",
    "\n",
    "for emp_num, info in problematic_emp_numbers.items():\n",
    "    persons = info['persons']\n",
    "    \n",
    "    # Check for various issues\n",
    "    names = [p['primary_name'] for p in persons]\n",
    "    \n",
    "    # Issue 1: Very different names (low fuzzy match)\n",
    "    if len(names) == 2:\n",
    "        if not fuzzy_name_match(names[0], names[1], threshold=50):\n",
    "            manual_review.append({\n",
    "                'Employee_Number': emp_num,\n",
    "                'Issue_Type': 'Very different names',\n",
    "                'Confidence_Level': 'Low',\n",
    "                'Names_Found': '; '.join(names),\n",
    "                'SSNIT_Count': sum(len(p['ssnits']) for p in persons),\n",
    "                'Details': 'No fuzzy name match, verify these are different people',\n",
    "                'Recommendation': 'Verify identity documents'\n",
    "            })\n",
    "    \n",
    "    # Issue 2: Same person with multiple permanent SSNITs\n",
    "    for person in persons:\n",
    "        perm_ssnits = [s for s in person['ssnits'] if classify_ssnit(s) == 'perm']\n",
    "        if len(perm_ssnits) > 1:\n",
    "            manual_review.append({\n",
    "                'Employee_Number': person['new_emp_num'],\n",
    "                'Issue_Type': 'Multiple permanent SSNITs',\n",
    "                'Confidence_Level': 'High',\n",
    "                'Names_Found': person['primary_name'],\n",
    "                'SSNIT_Count': len(perm_ssnits),\n",
    "                'Details': f\"Same name but {len(perm_ssnits)} permanent SSNITs: {', '.join(perm_ssnits)}\",\n",
    "                'Recommendation': 'Verify - likely different people with same name'\n",
    "            })\n",
    "    \n",
    "    # Issue 3: Same person with multiple temp SSNITs\n",
    "    for person in persons:\n",
    "        temp_ssnits = [s for s in person['ssnits'] if classify_ssnit(s) == 'temp']\n",
    "        if len(temp_ssnits) > 1:\n",
    "            manual_review.append({\n",
    "                'Employee_Number': person['new_emp_num'],\n",
    "                'Issue_Type': 'Multiple temp SSNITs',\n",
    "                'Confidence_Level': 'Medium',\n",
    "                'Names_Found': person['primary_name'],\n",
    "                'SSNIT_Count': len(temp_ssnits),\n",
    "                'Details': f\"Same name with {len(temp_ssnits)} temp SSNITs: {', '.join(temp_ssnits)}\",\n",
    "                'Recommendation': 'Check if sequential temporary assignments or different people'\n",
    "            })\n",
    "\n",
    "df_review = pd.DataFrame(manual_review)\n",
    "\n",
    "if len(df_review) > 0:\n",
    "    output_file = f\"{OUTPUT_DIR}\\\\Records_For_Manual_Review.csv\"\n",
    "    df_review.to_csv(output_file, index=False)\n",
    "    print(f\" Saved: {output_file}\")\n",
    "    print(f\"  Records flagged: {len(df_review)}\")\n",
    "else:\n",
    "    print(\" No records flagged for manual review\")\n",
    "\n",
    "\n",
    "# CELL 13: Generate Output File 5 - Reassigned_Employee_Numbers_Register.xlsx\n",
    "# =============================================================================\n",
    "# OUTPUT FILE 5: Reassigned_Employee_Numbers_Register.xlsx\n",
    "# =============================================================================\n",
    "\n",
    "print(\"\\nGenerating Reassigned_Employee_Numbers_Register.xlsx...\")\n",
    "\n",
    "# Sheet 1: Reassigned Employees\n",
    "reassigned = [p for p in all_persons if p['status'] == 'Reassigned']\n",
    "sheet1_data = []\n",
    "\n",
    "for person in reassigned:\n",
    "    ssnits = person['ssnits']\n",
    "    sheet1_data.append({\n",
    "        'New_Emp_No': person['new_emp_num'],\n",
    "        'Employee_Name': person['primary_name'],\n",
    "        'SSNIT_1': ssnits[0] if len(ssnits) > 0 else '',\n",
    "        'SSNIT_2': ssnits[1] if len(ssnits) > 1 else '',\n",
    "        'Old_Emp_No': person['original_emp_num'],\n",
    "        'Record_Count': person['count'],\n",
    "        'Reason': person['reason'],\n",
    "        'Date': datetime.now().strftime('%Y-%m-%d')\n",
    "    })\n",
    "\n",
    "df_sheet1 = pd.DataFrame(sheet1_data)\n",
    "\n",
    "# Sheet 2: Kept Original Numbers\n",
    "kept = [p for p in all_persons if p['status'] == 'Kept' and p['original_emp_num'] in problematic_emp_numbers]\n",
    "sheet2_data = []\n",
    "\n",
    "for person in kept:\n",
    "    ssnits = person['ssnits']\n",
    "    sheet2_data.append({\n",
    "        'Employee_No': person['new_emp_num'],\n",
    "        'Employee_Name': person['primary_name'],\n",
    "        'SSNIT_1': ssnits[0] if len(ssnits) > 0 else '',\n",
    "        'SSNIT_2': ssnits[1] if len(ssnits) > 1 else '',\n",
    "        'Record_Count': person['count'],\n",
    "        'Reason_Kept': person['reason']\n",
    "    })\n",
    "\n",
    "df_sheet2 = pd.DataFrame(sheet2_data)\n",
    "\n",
    "# Sheet 3: Quick Search (all persons)\n",
    "sheet3_data = []\n",
    "\n",
    "for person in all_persons:\n",
    "    ssnits = person['ssnits']\n",
    "    \n",
    "    # Add by name\n",
    "    sheet3_data.append({\n",
    "        'Search_Type': 'Name',\n",
    "        'Search_Value': person['primary_name'],\n",
    "        'Result_Type': person['status'],\n",
    "        'Old_Emp_No': person['original_emp_num'],\n",
    "        'New_Emp_No': person['new_emp_num'],\n",
    "        'Person_Name': person['primary_name'],\n",
    "        'SSNIT_1': ssnits[0] if len(ssnits) > 0 else '',\n",
    "        'SSNIT_2': ssnits[1] if len(ssnits) > 1 else ''\n",
    "    })\n",
    "    \n",
    "    # Add by each SSNIT\n",
    "    for ssnit in ssnits:\n",
    "        if ssnit and ssnit != 'UNKNOWN':\n",
    "            sheet3_data.append({\n",
    "                'Search_Type': 'SSNIT',\n",
    "                'Search_Value': ssnit,\n",
    "                'Result_Type': person['status'],\n",
    "                'Old_Emp_No': person['original_emp_num'],\n",
    "                'New_Emp_No': person['new_emp_num'],\n",
    "                'Person_Name': person['primary_name'],\n",
    "                'SSNIT_1': ssnits[0] if len(ssnits) > 0 else '',\n",
    "                'SSNIT_2': ssnits[1] if len(ssnits) > 1 else ''\n",
    "            })\n",
    "    \n",
    "    # Add by old employee number\n",
    "    sheet3_data.append({\n",
    "        'Search_Type': 'Old_Emp_No',\n",
    "        'Search_Value': person['original_emp_num'],\n",
    "        'Result_Type': person['status'],\n",
    "        'Old_Emp_No': person['original_emp_num'],\n",
    "        'New_Emp_No': person['new_emp_num'],\n",
    "        'Person_Name': person['primary_name'],\n",
    "        'SSNIT_1': ssnits[0] if len(ssnits) > 0 else '',\n",
    "        'SSNIT_2': ssnits[1] if len(ssnits) > 1 else ''\n",
    "    })\n",
    "\n",
    "df_sheet3 = pd.DataFrame(sheet3_data)\n",
    "\n",
    "# Sheet 4: Statistics Dashboard\n",
    "sheet4_data = {\n",
    "    'Metric': [\n",
    "        'Total Records Processed',\n",
    "        'Unique Employee Numbers (Before)',\n",
    "        'Unique Employee Numbers (After)',\n",
    "        'New Numbers Generated',\n",
    "        'Employee Numbers That Had Sharing',\n",
    "        'People Who Kept Original Numbers',\n",
    "        'People Reassigned New Numbers',\n",
    "        '',\n",
    "        '=== ISSUE BREAKDOWN ===',\n",
    "        '2+ Temporary SSNITs Detected',\n",
    "        '2+ Permanent SSNITs Detected',\n",
    "        'Name Groups Merged by Shared SSNIT',\n",
    "        'Records with UNKNOWN SSNIT Removed'\n",
    "    ],\n",
    "    'Value': [\n",
    "        len(df),\n",
    "        df['Employee_Number'].nunique(),\n",
    "        df_corrected['Employee_Number'].nunique(),\n",
    "        next_number - max_number - 1,\n",
    "        len(problematic_emp_numbers),\n",
    "        kept_count,\n",
    "        reassigned_count,\n",
    "        '',\n",
    "        '',\n",
    "        temp_violations,\n",
    "        perm_violations,\n",
    "        shared_ssnit_merges,\n",
    "        len(df) - len(df_corrected)\n",
    "    ]\n",
    "}\n",
    "\n",
    "df_sheet4 = pd.DataFrame(sheet4_data)\n",
    "\n",
    "# Write Excel file\n",
    "output_file = f\"{OUTPUT_DIR}\\\\Reassigned_Employee_Numbers_Register.xlsx\"\n",
    "\n",
    "with pd.ExcelWriter(output_file, engine='openpyxl') as writer:\n",
    "    df_sheet1.to_excel(writer, sheet_name='Reassigned Employees', index=False)\n",
    "    df_sheet2.to_excel(writer, sheet_name='Kept Original Numbers', index=False)\n",
    "    df_sheet3.to_excel(writer, sheet_name='Quick Search', index=False)\n",
    "    df_sheet4.to_excel(writer, sheet_name='Statistics Dashboard', index=False)\n",
    "    \n",
    "    # Format the sheets\n",
    "    workbook = writer.book\n",
    "    \n",
    "    # Format Sheet 1\n",
    "    ws1 = workbook['Reassigned Employees']\n",
    "    for cell in ws1[1]:\n",
    "        cell.font = Font(bold=True)\n",
    "        cell.fill = PatternFill(start_color='366092', end_color='366092', fill_type='solid')\n",
    "        cell.font = Font(bold=True, color='FFFFFF')\n",
    "    \n",
    "    # Format Sheet 2\n",
    "    ws2 = workbook['Kept Original Numbers']\n",
    "    for cell in ws2[1]:\n",
    "        cell.font = Font(bold=True)\n",
    "        cell.fill = PatternFill(start_color='70AD47', end_color='70AD47', fill_type='solid')\n",
    "        cell.font = Font(bold=True, color='FFFFFF')\n",
    "    \n",
    "    # Format Sheet 3\n",
    "    ws3 = workbook['Quick Search']\n",
    "    for cell in ws3[1]:\n",
    "        cell.font = Font(bold=True)\n",
    "        cell.fill = PatternFill(start_color='FFC000', end_color='FFC000', fill_type='solid')\n",
    "        cell.font = Font(bold=True, color='000000')\n",
    "    \n",
    "    # Format Sheet 4\n",
    "    ws4 = workbook['Statistics Dashboard']\n",
    "    for cell in ws4[1]:\n",
    "        cell.font = Font(bold=True)\n",
    "        cell.fill = PatternFill(start_color='5B9BD5', end_color='5B9BD5', fill_type='solid')\n",
    "        cell.font = Font(bold=True, color='FFFFFF')\n",
    "\n",
    "print(f\" Saved: {output_file}\")\n",
    "print(f\"  Sheet 1: {len(df_sheet1)} reassigned employees\")\n",
    "print(f\"  Sheet 2: {len(df_sheet2)} kept original numbers\")\n",
    "print(f\"  Sheet 3: {len(df_sheet3)} searchable records\")\n",
    "print(f\"  Sheet 4: Statistics dashboard\")\n",
    "\n",
    "\n",
    "# CELL 14: Final Summary and Verification\n",
    "# =============================================================================\n",
    "# FINAL SUMMARY AND VERIFICATION\n",
    "# =============================================================================\n",
    "\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"PROCESSING COMPLETE!\")\n",
    "print(\"=\" * 80)\n",
    "print(f\"\\nExecution Time: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\")\n",
    "print(\"\\nSUMMARY STATISTICS:\")\n",
    "print(f\"  Total records processed: {len(df):,}\")\n",
    "print(f\"  Unique employee numbers (before): {df['Employee_Number'].nunique():,}\")\n",
    "print(f\"  Unique employee numbers (after): {df_corrected['Employee_Number'].nunique():,}\")\n",
    "print(f\"  New employee numbers generated: {next_number - max_number - 1:,}\")\n",
    "print(f\"  Employee numbers with multiple people: {len(problematic_emp_numbers):,}\")\n",
    "print(f\"  People who kept original numbers: {kept_count:,}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
