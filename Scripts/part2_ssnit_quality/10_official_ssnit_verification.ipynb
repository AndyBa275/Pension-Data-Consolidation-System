{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68557337-83a3-4e1f-8c7a-497edc262250",
   "metadata": {},
   "outputs": [],
   "source": [
    "```python\n",
    "import pandas as pd\n",
    "import re\n",
    "from fuzzywuzzy import fuzz\n",
    "import numpy as np\n",
    "from collections import defaultdict\n",
    "\n",
    "# File paths\n",
    "psweps_path = r\"C:\\Users\\spt-admin\\Desktop\\NEW\\psweps.xlsx\"\n",
    "gtcl_path = r\"C:\\Users\\spt-admin\\Desktop\\NEW\\GTCL.xlsx\"\n",
    "output_path = r\"C:\\Users\\spt-admin\\Desktop\\NEW\\SSNIT_MATCH_EMP.xlsx\"\n",
    "\n",
    "# Load the data\n",
    "print(\"Loading files...\")\n",
    "psweps_df = pd.read_excel(psweps_path)\n",
    "gtcl_df = pd.read_excel(gtcl_path)\n",
    "\n",
    "print(f\"PSWEPS loaded: {len(psweps_df)} rows\")\n",
    "print(f\"GTCL loaded: {len(gtcl_df)} rows\")\n",
    "print(f\"PSWEPS columns: {psweps_df.columns.tolist()}\")\n",
    "print(f\"GTCL columns: {gtcl_df.columns.tolist()}\")\n",
    "\n",
    "# Step 1: Clean individual identifier (no pipe splitting here)\n",
    "def clean_identifier(value):\n",
    "    if pd.isna(value):\n",
    "        return ''\n",
    "    # Convert to string, strip whitespace, remove special characters\n",
    "    value = str(value).strip()\n",
    "    value = re.sub(r'[^\\w]', '', value)  # Remove non-alphanumeric\n",
    "    return value.upper()\n",
    "\n",
    "# Check if identifier is invalid\n",
    "def is_invalid_identifier(value):\n",
    "    if pd.isna(value) or value == '':\n",
    "        return True\n",
    "    value_str = str(value).strip().upper()\n",
    "    \n",
    "    # Exact matches for invalid values\n",
    "    invalid_values = ['', '0', 'UNKNOWN', 'NAN', 'NA', 'N/A', 'NONE']\n",
    "    if value_str in invalid_values:\n",
    "        return True\n",
    "    \n",
    "    # Check if it contains certain keywords\n",
    "    invalid_keywords = ['TRUST', 'UNKNOWN', 'NO_SSF_NUMBER', 'UNKNO', 'NOSSF']\n",
    "    for keyword in invalid_keywords:\n",
    "        if keyword in value_str:\n",
    "            return True\n",
    "    \n",
    "    return False\n",
    "\n",
    "# Split pipe-separated values and clean each\n",
    "def parse_and_clean_identifiers(value):\n",
    "    \"\"\"\n",
    "    Takes a value like \"H016310070030|NO_SSF_NUMBER\" \n",
    "    Returns a list of cleaned valid identifiers: [\"H016310070030\"]\n",
    "    \"\"\"\n",
    "    if pd.isna(value):\n",
    "        return []\n",
    "    \n",
    "    # Split by pipe\n",
    "    parts = str(value).split('|')\n",
    "    \n",
    "    # Clean each part and filter out invalid ones\n",
    "    cleaned = []\n",
    "    for part in parts:\n",
    "        cleaned_part = clean_identifier(part)\n",
    "        if not is_invalid_identifier(cleaned_part):\n",
    "            cleaned.append(cleaned_part)\n",
    "    \n",
    "    return cleaned\n",
    "\n",
    "# Apply to PSWEPS - create lists of valid identifiers\n",
    "print(\"\\nParsing pipe-separated identifiers...\")\n",
    "psweps_df['SSNIT_LIST'] = psweps_df['SSNIT_Number'].apply(parse_and_clean_identifiers)\n",
    "psweps_df['EMPNUM_LIST'] = psweps_df['Employee_Number'].apply(parse_and_clean_identifiers)\n",
    "\n",
    "# Apply to GTCL - single value (no pipes expected)\n",
    "gtcl_df['CLEANED_SSNIT_NO'] = gtcl_df['SSNIT No.'].apply(clean_identifier)\n",
    "gtcl_df['VALID_SSNIT'] = ~gtcl_df['CLEANED_SSNIT_NO'].apply(is_invalid_identifier)\n",
    "\n",
    "print(f\"PSWEPS - Records with valid SSNIT: {(psweps_df['SSNIT_LIST'].str.len() > 0).sum()}\")\n",
    "print(f\"PSWEPS - Records with valid EmpNum: {(psweps_df['EMPNUM_LIST'].str.len() > 0).sum()}\")\n",
    "print(f\"GTCL - Records with valid SSNIT: {gtcl_df['VALID_SSNIT'].sum()}\")\n",
    "\n",
    "# Step 2: Build FAST lookup dictionaries\n",
    "print(\"\\nBuilding fast lookup dictionaries...\")\n",
    "\n",
    "# SSNIT lookup: {ssnit_value: [list of psweps row indices]}\n",
    "ssnit_lookup = defaultdict(list)\n",
    "for idx, row in psweps_df.iterrows():\n",
    "    for ssnit in row['SSNIT_LIST']:\n",
    "        ssnit_lookup[ssnit].append(idx)\n",
    "\n",
    "# Employee Number lookup: {empnum_value: [list of psweps row indices]}\n",
    "empnum_lookup = defaultdict(list)\n",
    "for idx, row in psweps_df.iterrows():\n",
    "    for empnum in row['EMPNUM_LIST']:\n",
    "        empnum_lookup[empnum].append(idx)\n",
    "\n",
    "print(f\"SSNIT lookup built: {len(ssnit_lookup)} unique SSNITs\")\n",
    "print(f\"EmpNum lookup built: {len(empnum_lookup)} unique Employee Numbers\")\n",
    "\n",
    "# Step 3: Parse and clean names\n",
    "def parse_name(name):\n",
    "    if pd.isna(name):\n",
    "        return []\n",
    "    \n",
    "    # Convert to string and clean\n",
    "    name = str(name).strip()\n",
    "    \n",
    "    # Remove quotes and extra spaces\n",
    "    name = name.replace(\"'\", \"\").replace('\"', '')\n",
    "    \n",
    "    # Replace commas with spaces\n",
    "    name = name.replace(',', ' ')\n",
    "    \n",
    "    # Split by whitespace and filter empty strings\n",
    "    parts = [p.strip().upper() for p in name.split() if p.strip() and len(p.strip()) > 1]\n",
    "    \n",
    "    return parts\n",
    "\n",
    "print(\"\\nParsing names...\")\n",
    "psweps_df['NAME_PARTS'] = psweps_df['Employee_Name'].apply(parse_name)\n",
    "gtcl_df['NAME_PARTS'] = gtcl_df['Name'].apply(parse_name)\n",
    "\n",
    "# Step 4: Fuzzy name matching function\n",
    "def calculate_name_similarity(name_parts_1, name_parts_2):\n",
    "    \"\"\"\n",
    "    Calculate similarity between two sets of name parts.\n",
    "    Returns: (match_count, avg_similarity_score)\n",
    "    \"\"\"\n",
    "    if not name_parts_1 or not name_parts_2:\n",
    "        return 0, 0\n",
    "    \n",
    "    matches = 0\n",
    "    total_similarity = 0\n",
    "    \n",
    "    for part1 in name_parts_1:\n",
    "        best_match_score = 0\n",
    "        for part2 in name_parts_2:\n",
    "            # Direct fuzzy matching\n",
    "            score = fuzz.ratio(part1, part2)\n",
    "            if score >= 85:\n",
    "                best_match_score = max(best_match_score, score)\n",
    "            # Check if one part is contained in the other (for concatenated names)\n",
    "            elif len(part1) >= 3 and len(part2) >= 3:\n",
    "                if part1 in part2 or part2 in part1:\n",
    "                    best_match_score = max(best_match_score, 90)\n",
    "        \n",
    "        if best_match_score >= 85:\n",
    "            matches += 1\n",
    "            total_similarity += best_match_score\n",
    "    \n",
    "    avg_similarity = total_similarity / matches if matches > 0 else 0\n",
    "    \n",
    "    return matches, avg_similarity\n",
    "\n",
    "# Step 5: FAST Matching logic using lookup dictionaries\n",
    "def find_best_match(gtcl_row, psweps_df, lookup_dict, match_type='SSNIT'):\n",
    "    \"\"\"\n",
    "    Find the best match in PSWEPS for a GTCL row using fast lookup.\n",
    "    match_type: 'SSNIT' or 'EMPNUM'\n",
    "    Returns: (sp_number, match_score, match_type, matched_identifier) or (None, 0, None, None)\n",
    "    \"\"\"\n",
    "    gtcl_identifier = gtcl_row['CLEANED_SSNIT_NO']\n",
    "    gtcl_name_parts = gtcl_row['NAME_PARTS']\n",
    "    \n",
    "    if is_invalid_identifier(gtcl_identifier):\n",
    "        return None, 0, None, None\n",
    "    \n",
    "    # Fast lookup - get candidate row indices instantly\n",
    "    candidate_indices = lookup_dict.get(gtcl_identifier, [])\n",
    "    \n",
    "    if len(candidate_indices) == 0:\n",
    "        return None, 0, None, None\n",
    "    \n",
    "    # Find best name match among candidates\n",
    "    best_match = None\n",
    "    best_score = 0\n",
    "    best_sp_number = None\n",
    "    matched_id = None\n",
    "    \n",
    "    for idx in candidate_indices:\n",
    "        candidate = psweps_df.iloc[idx]\n",
    "        psweps_name_parts = candidate['NAME_PARTS']\n",
    "        match_count, avg_similarity = calculate_name_similarity(gtcl_name_parts, psweps_name_parts)\n",
    "        \n",
    "        # Require at least 2 matching name parts with 85% similarity\n",
    "        if match_count >= 2 and avg_similarity >= 85:\n",
    "            if avg_similarity > best_score:\n",
    "                best_score = avg_similarity\n",
    "                best_sp_number = candidate['SP_NUMBER']\n",
    "                best_match = match_type\n",
    "                matched_id = gtcl_identifier\n",
    "    \n",
    "    return best_sp_number, best_score, best_match, matched_id\n",
    "\n",
    "# Step 6: Process each GTCL row with FAST lookups\n",
    "print(\"\\nMatching GTCL records to PSWEPS (FAST MODE)...\")\n",
    "results = []\n",
    "\n",
    "for idx, gtcl_row in gtcl_df.iterrows():\n",
    "    # Try SSNIT match first (using fast lookup)\n",
    "    sp_number, score, match_type, matched_id = find_best_match(\n",
    "        gtcl_row, psweps_df, ssnit_lookup, match_type='SSNIT'\n",
    "    )\n",
    "    \n",
    "    # If SSNIT match failed, try Employee Number match (using fast lookup)\n",
    "    if sp_number is None:\n",
    "        sp_number, score, match_type, matched_id = find_best_match(\n",
    "            gtcl_row, psweps_df, empnum_lookup, match_type='EMPNUM'\n",
    "        )\n",
    "    \n",
    "    results.append({\n",
    "        'SP_NUMBER': sp_number if sp_number else '',\n",
    "        'MATCH_TYPE': match_type if match_type else '',\n",
    "        'MATCH_SCORE': score if score > 0 else '',\n",
    "        'MATCHED_ID': matched_id if matched_id else ''\n",
    "    })\n",
    "    \n",
    "    if (idx + 1) % 500 == 0:\n",
    "        print(f\"Processed {idx + 1}/{len(gtcl_df)} records...\")\n",
    "\n",
    "print(f\"Processed all {len(gtcl_df)} records!\")\n",
    "\n",
    "# Create results dataframe\n",
    "results_df = pd.DataFrame(results)\n",
    "\n",
    "# Insert SP_NUMBER into Column A of GTCL\n",
    "gtcl_df.insert(0, 'SP_NUMBER', results_df['SP_NUMBER'])\n",
    "gtcl_df.insert(1, 'MATCH_TYPE', results_df['MATCH_TYPE'])\n",
    "gtcl_df.insert(2, 'MATCH_SCORE', results_df['MATCH_SCORE'])\n",
    "gtcl_df.insert(3, 'MATCHED_ID', results_df['MATCHED_ID'])\n",
    "\n",
    "# Remove temporary columns\n",
    "gtcl_df = gtcl_df.drop(columns=['CLEANED_SSNIT_NO', 'VALID_SSNIT', 'NAME_PARTS'])\n",
    "\n",
    "print(f\"\\nMatching complete!\")\n",
    "\n",
    "# Step 7: Generate statistics\n",
    "total_records = len(gtcl_df)\n",
    "ssnit_matches = (gtcl_df['MATCH_TYPE'] == 'SSNIT').sum()\n",
    "empnum_matches = (gtcl_df['MATCH_TYPE'] == 'EMPNUM').sum()\n",
    "no_matches = (gtcl_df['SP_NUMBER'] == '').sum()\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"MATCHING STATISTICS\")\n",
    "print(\"=\"*80)\n",
    "print(f\"Total GTCL records:          {total_records}\")\n",
    "print(f\"Matched via SSNIT:           {ssnit_matches} ({ssnit_matches/total_records*100:.1f}%)\")\n",
    "print(f\"Matched via Employee Number: {empnum_matches} ({empnum_matches/total_records*100:.1f}%)\")\n",
    "print(f\"No match found:              {no_matches} ({no_matches/total_records*100:.1f}%)\")\n",
    "print(f\"Total matched:               {ssnit_matches + empnum_matches} ({(ssnit_matches + empnum_matches)/total_records*100:.1f}%)\")\n",
    "\n",
    "# Step 8: Save to Excel\n",
    "print(f\"\\nSaving to Excel...\")\n",
    "gtcl_df.to_excel(output_path, index=False, engine='openpyxl')\n",
    "\n",
    "print(f\"Saved to: {output_path}\")\n",
    "\n",
    "# Show sample of results\n",
    "print(\"\\nSample of matched results:\")\n",
    "matched_sample = gtcl_df[gtcl_df['SP_NUMBER'] != ''][['SP_NUMBER', 'MATCH_TYPE', 'MATCH_SCORE', 'MATCHED_ID', 'Name', 'SSNIT No.']].head(10)\n",
    "if len(matched_sample) > 0:\n",
    "    print(matched_sample)\n",
    "\n",
    "print(\"\\nSample of unmatched results:\")\n",
    "unmatched = gtcl_df[gtcl_df['SP_NUMBER'] == ''][['Name', 'SSNIT No.']].head(5)\n",
    "if len(unmatched) > 0:\n",
    "    print(unmatched)\n",
    "else:\n",
    "    print(\"No unmatched records!\")\n",
    "\n",
    "# Show example of pipe-separated handling\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"EXAMPLE: Checking Batumi Mahamudu case\")\n",
    "print(\"=\"*80)\n",
    "Batumi_psweps = psweps_df[psweps_df['Employee_Name'].str.contains('Batumi', case=False, na=False)]\n",
    "if len(Batumi_psweps) > 0:\n",
    "    for idx, row in Batumi_psweps.head(2).iterrows():\n",
    "        print(f\"\\nPSWEPS Record:\")\n",
    "        print(f\"  Name: {row['Employee_Name']}\")\n",
    "        print(f\"  SSNIT_Number (raw): {row['SSNIT_Number']}\")\n",
    "        print(f\"  SSNIT_LIST (parsed): {row['SSNIT_LIST']}\")\n",
    "        print(f\"  SP_NUMBER: {row['SP_NUMBER']}\")\n",
    "\n",
    "Batumi_gtcl = gtcl_df[gtcl_df['Name'].str.contains('Batumi', case=False, na=False)]\n",
    "if len(Batumi_gtcl) > 0:\n",
    "    for idx, row in Batumi_gtcl.head(2).iterrows():\n",
    "        print(f\"\\nGTCL Record:\")\n",
    "        print(f\"  Name: {row['Name']}\")\n",
    "        print(f\"  SSNIT No.: {row['SSNIT No.']}\")\n",
    "        print(f\"  SP_NUMBER (matched): {row['SP_NUMBER']}\")\n",
    "        print(f\"  MATCH_TYPE: {row['MATCH_TYPE']}\")\n",
    "        print(f\"  MATCHED_ID: {row['MATCHED_ID']}\")\n",
    "```"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
